{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логистическая регрессия и анализ изображений\n",
    "\n",
    "\n",
    "В этом ноутбуке предлагается построить классификатор изображений на основе логистической регрессии.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - Пакеты ##\n",
    "\n",
    "Используемые пакеты:\n",
    "- [numpy](www.numpy.org) - всё понятно.\n",
    "- [h5py](http://www.h5py.org) для работы с датасетом, сохранённым в виде H5 файла.\n",
    "- [matplotlib](http://matplotlib.org) для рисования графиков.\n",
    "- [PIL](http://www.pythonware.com/products/pil/) и [scipy](https://www.scipy.org/) используются для тестирования своей модели на собственных картинках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Постановка задачи ##\n",
    "\n",
    "**Задача**: Есть датасет (\"catvnoncat.h5\") состоящий из:\n",
    "    - обучающей выборки из m_train изображений, помеченных \"cat\" (y=1) или \"non-cat\" (y=0)\n",
    "    - тестовой выборки m_test изображений, помеченных \"cat\" или \"non-cat\"\n",
    "    - каждое цветное изображение имеет размер (num_px, num_px, 3), где 3 - число каналов (RGB).\n",
    "    Таким образом, каждый слой - квадрат размера num_px x num_px$.\n",
    "\n",
    "Давайте построим простой алгоритм классификации изображений на классы \"cat\"/\"non-cat\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"LogReg_kiank.png\" style=\"width:650px;height:400px;\">\n",
    "\n",
    "**Recap**:\n",
    "\n",
    "Для каждого примера $x^{(i)}$:\n",
    "$$z^{(i)} = w^T x^{(i)} + b \\tag{1}$$\n",
    "$$\\hat{y}^{(i)} = a^{(i)} = sigmoid(z^{(i)})\\tag{2}$$ \n",
    "$$ \\mathcal{L}(a^{(i)}, y^{(i)}) =  - y^{(i)}  \\log(a^{(i)}) - (1-y^{(i)} )  \\log(1-a^{(i)})\\tag{3}$$\n",
    "\n",
    "Функция потерь:\n",
    "$$ J = \\frac{1}{m} \\sum_{i=1}^m \\mathcal{L}(a^{(i)}, y^{(i)})\\tag{6}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Загрузка данных и визуализация ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    train_data = h5py.File(r\"../data/train_catvnoncat.h5\", \"r\")\n",
    "    train_set_x_orig = np.array(train_data[\"train_set_x\"][:]) # признаки\n",
    "    train_set_y_orig = np.array(train_data[\"train_set_y\"][:]) # метки классов\n",
    "\n",
    "    test_data = h5py.File(r\"../data/test_catvnoncat.h5\", \"r\")\n",
    "    test_set_x_orig = np.array(test_data[\"test_set_x\"][:]) # признаки\n",
    "    test_set_y_orig = np.array(test_data[\"test_set_y\"][:]) # метки классов\n",
    "\n",
    "    classes = np.array(test_data[\"list_classes\"][:]) # the list of classes\n",
    "    classes = np.array(list(map(lambda x: x.decode('utf-8'), classes)))\n",
    "    \n",
    "    train_set_y = train_set_y_orig.reshape(train_set_y_orig.shape[0])\n",
    "    test_set_y = test_set_y_orig.reshape(test_set_y_orig.shape[0])\n",
    "    return train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цветные изображения в формате RGB представлены в виде трёхмерных numpy.array.\n",
    "\n",
    "Порядок измерений $H \\times W \\times C$: $H$ -- высота, $W$ - ширина и $C$ - число каналов.\n",
    "\n",
    "Значение каждого пиксела находится в интервале $[0;255]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a582532e4c214fc291ed020d83209ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=208), Output()), _dom_classes=('widget-interact'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_image_interact(i=0)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "def show_image_interact(i=0):\n",
    "    f, ax = plt.subplots(1,4, figsize=(15,20), sharey=True)\n",
    "    \n",
    "    ax[0].imshow(train_set_x_orig[i])\n",
    "    ax[0].set_title('RGB image')\n",
    "    ax[1].imshow(train_set_x_orig[i][:,:,0], cmap='gray')\n",
    "    ax[1].set_title('R channel')\n",
    "    ax[2].imshow(train_set_x_orig[i][:,:,1], cmap='gray')\n",
    "    ax[2].set_title('G channel')\n",
    "    ax[3].imshow(train_set_x_orig[i][:,:,2], cmap='gray')\n",
    "    ax[3].set_title('B channel')\n",
    "    \n",
    "    print(\"y = {} belongs to '{}' class.\".format(str(train_set_y[i]),classes[np.squeeze(train_set_y[i])]))\n",
    "\n",
    "interact(show_image_interact,\n",
    "         i=widgets.IntSlider(min=0, max=len(train_set_y)-1, step=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При работе с данными полезно будет сохранить размерности входных изображений для дальнейшей обработки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки: m_train = 209\n",
      "Размер тестовой выборки: m_test = 50\n",
      "Ширина/Высота каждого изображения: src_size = 64\n",
      "Размерны трёхмерной матрицы для каждого изображения: (64, 64, 3)\n",
      "Размерность train_set_x: (209, 64, 64, 3)\n",
      "Размерность train_set_y: (209,)\n",
      "Размерность test_set_x: (50, 64, 64, 3)\n",
      "Размерность test_set_y: (50,)\n"
     ]
    }
   ],
   "source": [
    "m_train = train_set_x_orig.shape[0]\n",
    "m_test = test_set_x_orig.shape[0]\n",
    "src_size = train_set_x_orig.shape[1]\n",
    "\n",
    "print (\"Размер обучающей выборки: m_train = \" + str(m_train))\n",
    "print (\"Размер тестовой выборки: m_test = \" + str(m_test))\n",
    "print (\"Ширина/Высота каждого изображения: src_size = \" + str(src_size))\n",
    "print (\"Размерны трёхмерной матрицы для каждого изображения: (\" + str(src_size) + \", \" + str(src_size) + \", 3)\")\n",
    "print (\"Размерность train_set_x: \" + str(train_set_x_orig.shape))\n",
    "print (\"Размерность train_set_y: \" + str(train_set_y.shape))\n",
    "print (\"Размерность test_set_x: \" + str(test_set_x_orig.shape))\n",
    "print (\"Размерность test_set_y: \" + str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Предварительная обработка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем входные изображения размера (num_px, num_px, 3) в вектор признаков размера (num_px $*$ num_px $*$ 3, 1), чтобы сформировать матрицы объект-признак в виде numpy-array для обучающей и тестовой выборок.\n",
    "\n",
    "Каждой строке матрицы объект-признак соответствует входное развёрнутое в вектор-строку изображение.\n",
    "\n",
    "Помимо этого, для предварительной обработки (препроцессинга) изображений применяют центрирование значений: из значения каждого пиксела вычитается среднее и делят полученное значение на среднеквадратичное отклонение значений пикселей всего изображения.\n",
    "\n",
    "Однако, на практике обычно просто делят значения пикселей на 255 (максимальное значение пикселя).\n",
    "\n",
    "Оформим эти шаги в функцию предварительной обработки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocessing_simple(data):\n",
    "    assert type(data) == np.ndarray\n",
    "    assert data.ndim == 4\n",
    "    \n",
    "    n,h,w,c = data.shape\n",
    "    data_vectorized = data.reshape(n, -1) # <ваш код>\n",
    "    data_normalized = data_vectorized / 255\n",
    "    \n",
    "    return data_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:\n",
      "Размеры train_set_x_vectorized:  (209, 12288)\n",
      "Размеры train_set_y:             (209,)\n",
      "Размеры классов 'cat'/'non-cat': 72 / 137\n",
      "Test set:\n",
      "Размеры test_set_x_vectorized:   (50, 12288)\n",
      "Размеры test_set_y:              (50,)\n",
      "Размеры классов 'cat'/'non-cat': 33 / 17\n"
     ]
    }
   ],
   "source": [
    "# Изменить размеры входных данных\n",
    "\n",
    "train_set_x_vectorized = image_preprocessing_simple(train_set_x_orig)\n",
    "test_set_x_vectorized = image_preprocessing_simple(test_set_x_orig)\n",
    "\n",
    "print('Train set:')\n",
    "print(\"Размеры train_set_x_vectorized:  {}\".format(str(train_set_x_vectorized.shape)))\n",
    "print(\"Размеры train_set_y:             {}\".format(str(train_set_y.shape)))\n",
    "print(\"Размеры классов 'cat'/'non-cat': {} / {}\".format(sum(train_set_y==1), sum(train_set_y==0)))\n",
    "print('Test set:')\n",
    "print(\"Размеры test_set_x_vectorized:   {}\".format(str(test_set_x_vectorized.shape)))\n",
    "print(\"Размеры test_set_y:              {}\".format(str(test_set_y.shape)))\n",
    "print(\"Размеры классов 'cat'/'non-cat': {} / {}\".format(sum(test_set_y==1), sum(test_set_y==0)))\n",
    "# print(\"Проверка результатов: \\n\\n\" + str(train_set_x_vectorized[0, 0:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос**: Какую метрику качества стоит использовать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Построение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность для простой модели с параметрами по умолчанию: 0.7200\n"
     ]
    }
   ],
   "source": [
    "clf.fit(train_set_x_vectorized, train_set_y)\n",
    "score = clf.score(test_set_x_vectorized, test_set_y)\n",
    "print('Точность для простой модели с параметрами по умолчанию: {:.4f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-мера для простой модели: 0.7667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "y_predicted = clf.predict(test_set_x_vectorized)\n",
    "print('F-мера для простой модели: {:.4f}'.format(f1_score(y_predicted, test_set_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"penalty\" : [\"l1\", \"l2\"],\n",
    "    \"C\" : np.logspace(-3,3,7)\n",
    "}\n",
    "\n",
    "clf = LogisticRegression(solver='liblinear')\n",
    "gscv = GridSearchCV(clf, params, scoring='f1', cv=2).fit(train_set_x_vectorized, train_set_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оптимальные параметры: {'C': 1.0, 'penalty': 'l2'}\n",
      "Наилучшая F-мера: 0.3732653983355778\n"
     ]
    }
   ],
   "source": [
    "print('Оптимальные параметры: {}'.format(gscv.best_params_))\n",
    "print('Наилучшая F-мера: {}'.format(gscv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal model hyperparameters accuracy score: 0.7667\n"
     ]
    }
   ],
   "source": [
    "best_clf = LogisticRegression(solver='liblinear', **gscv.best_params_)\n",
    "best_clf.fit(train_set_x_vectorized, train_set_y)\n",
    "\n",
    "y_predicted = best_clf.predict(test_set_x_vectorized)\n",
    "print('Optimal model hyperparameters accuracy score: {:.4f}'.format(f1_score(y_predicted, test_set_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Анализ ошибок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_outlier = (y_predicted != test_set_y)\n",
    "test_outliers_x, test_outliers_y, predicted_y = test_set_x_orig[is_outlier], test_set_y[is_outlier], y_predicted[is_outlier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_outliers(i=0):\n",
    "    f = plt.figure(figsize=(5,5))\n",
    "    plt.imshow(test_outliers_x[i])\n",
    "    plt.title('RGB image')\n",
    "    \n",
    "    fmt_string = \"Sample belongs to '{}' class, but '{}' is predicted'\"\n",
    "    print(fmt_string.format(classes[test_outliers_y[i]], classes[predicted_y[i]]))\n",
    "\n",
    "interact(show_image_outliers,\n",
    "         i=widgets.IntSlider(min=0, max=len(test_outliers_y)-1, step=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопросы**: Как по-вашему можно повысить точность? Каким недостатком обладает данный подход к классификации?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Модель с аугментациями"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно увеличить количество данных для обучения?\n",
    "\n",
    "Сформировать новые примеры из уже имеющихся!\n",
    "\n",
    "Например, можно пополнить class 'cat' обучающей выборки зеркально отображёнными изображениями котов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_sample(src, label):\n",
    "    if label == 0:\n",
    "        return src[np.newaxis, :, :, :], label\n",
    "    else:\n",
    "        return np.concatenate([np.fliplr(src)[np.newaxis,:,:,:], src[np.newaxis,:,:,:]], axis=0), np.array([label,label])\n",
    "\n",
    "def image_preprocessing_augment(data, labels):\n",
    "    assert type(data) == np.ndarray\n",
    "    assert data.ndim == 4\n",
    "    \n",
    "    ## ВАШ КОД ##\n",
    "    \n",
    "    data_label_list = [augment_sample(src, label) for src, label in zip(data,labels)]\n",
    "    data_augmented, labels_augmented = zip(*data_label_list)\n",
    "    data_augmented = np.concatenate(data_augmented, axis=0)\n",
    "    labels_augmented = np.hstack(labels_augmented)\n",
    "    \n",
    "    ## ВАШ КОД ЗАКАНЧИВАЕТСЯ ЗДЕСЬ ##\n",
    "    \n",
    "    n,h,w,c = data_augmented.shape\n",
    "    data_vectorized = data_augmented.reshape(n, -1) # <ваш код>\n",
    "    data_normalized = data_vectorized / 255\n",
    "    \n",
    "    return data_normalized, labels_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x_augmented, train_set_y_augmented = image_preprocessing_augment(train_set_x_orig, train_set_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver='liblinear')\n",
    "clf.fit(train_set_x_augmented, train_set_y_augmented)\n",
    "y_pred = clf.predict(test_set_x_vectorized)\n",
    "print('F-мера для модели с аугментациями: {:.4f}'.format(f1_score(y_pred, test_set_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Проверьте работу классификатора на своей картинке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Библиотека [OpenCV](https://opencv.org) для работы с изображениями для [python](https://pypi.org/project/opencv-python/):\n",
    "\n",
    "`pip install opencv-python`\n",
    "\n",
    "Вместе с contrib-модулями:\n",
    "\n",
    "`pip install opencv-contrib-python`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f60c074f5e98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Путь к картинке на вашем ПК\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cat-non-cat.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Считываем картинку через scipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Путь к картинке на вашем ПК\n",
    "fname = \"cat-non-cat.jpg\"\n",
    "# Считываем картинку через scipy\n",
    "src = cv2.cvtColor(cv2.imread((fname)), cv2.COLOR_BGR2RGB)\n",
    "src_resized = cv2.resize(src, (src_size,src_size), interpolation=cv2.INTER_LINEAR).reshape(1, src_size*src_size*3)\n",
    "my_image_predict = clf.predict(src_resized)[0]\n",
    "\n",
    "plt.imshow(image)\n",
    "print(\"Алгоритм говорит, что это '{}': {}\".format(my_image_predict, classes[my_image_predict]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cv2\n",
      "\u001b[31m  Could not find a version that satisfies the requirement cv2 (from versions: )\u001b[0m\n",
      "\u001b[31mNo matching distribution found for cv2\u001b[0m\n",
      "\u001b[33mYou are using pip version 19.0.2, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "XaIWT",
   "launcher_item_id": "zAgPl"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
